import os

"""
Automatically create Modules for each activation function.
"""

# autogenerate a file containing all activation functions as modules

file = "../parametricmatrixmodels/modules/_autogenerated_activationfuncs.py"

if os.path.exists(file):
    raise FileExistsError(
        f"File {file} already exists. Please remove it before running this"
        " script."
    )

imports = ["import jax", "from .activationbase import ActivationBase"]

funcs = {
    "ReLU": "jax.nn.relu",
    "ReLU6": "jax.nn.relu6",
    "Sigmoid": "jax.nn.sigmoid",
    "Softplus": "jax.nn.softplus",
    "SparsePlus": "jax.nn.sparse_plus",
    "SparseSigmoid": "jax.nn.sparse_sigmoid",
    "SoftSign": "jax.nn.soft_sign",
    "SiLU": "jax.nn.silu",
    "Swish": "jax.nn.swish",
    "LogSigmoid": "jax.nn.log_sigmoid",
    "LeakyReLU": "jax.nn.leaky_relu",
    "HardSigmoid": "jax.nn.hard_sigmoid",
    "HardSiLU": "jax.nn.hard_silu",
    "HardSwish": "jax.nn.hard_swish",
    "HardTanh": "jax.nn.hard_tanh",
    "ELU": "jax.nn.elu",
    "CELU": "jax.nn.celu",
    "SELU": "jax.nn.selu",
    "GELU": "jax.nn.gelu",
    "GLU": "jax.nn.glu",
    "SquarePlus": "jax.nn.squareplus",
    "Mish": "jax.nn.mish",
    "Identity": "jax.nn.identity",
    "Softmax": "jax.nn.softmax",
    "LogSoftmax": "jax.nn.log_softmax",
    "LogSumExp": "jax.nn.logsumexp",
    "Standardize": "jax.nn.standardize",
    "OneHot": "jax.nn.one_hot",
    # "DotProductAttention": "jax.nn.dot_product_attention",
    # "ScaledMatmul": "jax.nn.scaled_matmul",
    # "ScaledDotGeneral": "jax.nn.scaled_dot_general",
    # Elementwise numpy functions
    "Abs": "jax.numpy.abs",
    "Absolute": "jax.numpy.absolute",
    "ACos": "jax.numpy.acos",
    "ACosh": "jax.numpy.acosh",
    "AMax": "jax.numpy.amax",
    "AMin": "jax.numpy.amin",
    "Angle": "jax.numpy.angle",
    "ArcCos": "jax.numpy.arccos",
    "ArcCosh": "jax.numpy.arccosh",
    "ArcSin": "jax.numpy.arcsin",
    "ArcSinh": "jax.numpy.arcsinh",
    "ArcTan": "jax.numpy.arctan",
    "ArcTan2": "jax.numpy.arctan2",
    "ArcTanh": "jax.numpy.arctanh",
    "ASin": "jax.numpy.asin",
    "ASinh": "jax.numpy.asinh",
    "ATan": "jax.numpy.atan",
    "ATanh": "jax.numpy.atanh",
    "Cbrt": "jax.numpy.cbrt",
    "Ceil": "jax.numpy.ceil",
    "Clip": "jax.numpy.clip",
    "Conj": "jax.numpy.conj",
    "Conjugate": "jax.numpy.conjugate",
    "Cos": "jax.numpy.cos",
    "Cosh": "jax.numpy.cosh",
    "Deg2Rad": "jax.numpy.deg2rad",
    "Degrees": "jax.numpy.degrees",
    "Exp": "jax.numpy.exp",
    "Exp2": "jax.numpy.exp2",
    "Expm1": "jax.numpy.expm1",
    "FAbs": "jax.numpy.fabs",
    "Fix": "jax.numpy.fix",
    "FloatPower": "jax.numpy.float_power",
    "Floor": "jax.numpy.floor",
    "FloorDivide": "jax.numpy.floor_divide",
    "FrExp": "jax.numpy.frexp",
    "I0": "jax.numpy.i0",
    "Imag": "jax.numpy.imag",
    "Invert": "jax.numpy.invert",
    "LDExp": "jax.numpy.ldexp",
    "Log": "jax.numpy.log",
    "Log10": "jax.numpy.log10",
    "Log1p": "jax.numpy.log1p",
    "Log2": "jax.numpy.log2",
    "NaNToNum": "jax.numpy.nan_to_num",
    "NanToNum": "jax.numpy.nan_to_num",
    "NextAfter": "jax.numpy.nextafter",
    "Packbits": "jax.numpy.packbits",
    "Piecewise": "jax.numpy.piecewise",
    "Positive": "jax.numpy.positive",
    "Pow": "jax.numpy.pow",
    "Power": "jax.numpy.power",
    "Rad2Deg": "jax.numpy.rad2deg",
    "Radians": "jax.numpy.radians",
    "Real": "jax.numpy.real",
    "Reciprocal": "jax.numpy.reciprocal",
    "RInt": "jax.numpy.rint",
    "Round": "jax.numpy.round",
    "Sign": "jax.numpy.sign",
    "Signbit": "jax.numpy.signbit",
    "Sin": "jax.numpy.sin",
    "Sinc": "jax.numpy.sinc",
    "Sinh": "jax.numpy.sinh",
    "Sqrt": "jax.numpy.sqrt",
    "Square": "jax.numpy.square",
    "Tan": "jax.numpy.tan",
    "Tanh": "jax.numpy.tanh",
    "Trunc": "jax.numpy.trunc",
    "Unpackbits": "jax.numpy.unpackbits",
}


def create_module(name: str, func: str) -> str:
    """
    Create a module class for the activation function.

    Parameters
    ----------
    name : str
        Name of the activation function.
    func : str
        Function to be used for the activation.

    Returns
    -------
    str
        The class definition as a string.
    """
    return f"""
class {name}(ActivationBase):
    \"\"\"
    Elementwise activation function for ``{func}``.

    See Also
    --------
    {func} : The function used for the elementwise activation.
    \"\"\"
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def name(self) -> str:
        return "{name}"

    def func(self, x: jax.numpy.ndarray) -> jax.numpy.ndarray:
        return {func}(x, *self.args, **self.kwargs)
"""


file_content = "\n".join(imports) + "\n\n"

for name, func in funcs.items():
    file_content += create_module(name, func) + "\n"

file_content += "\n# This file is autogenerated. Do not edit manually.\n"

with open(file, "w") as f:
    f.write(file_content)
